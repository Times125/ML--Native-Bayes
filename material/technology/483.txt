  Driverless vehicles may seem unfamiliar now, but over the coming years you'll start to encounter - or even use them - on a daily basis. Will it mean the end of the driving licence and changes to the rules of the road? It's not uncommon to see a squat white droid trundling along the streets of Greenwich, south-east London, as it delivers takeaway food to the borough's residents at 4mph. In Paris and Helsinki, robot buses are shuttling passengers along city streets, while in Colorado an 18-wheeler truck drove beer 120 miles down a highway - without a driver. Around the world, projects like these are under way to help develop the technology that will ultimately bring driverless cars and other vehicles to our roads. But alongside the issue of whether they will work is another big question: how will pedestrians, cyclists and human drivers be kept safe? Sales of self-driving vehicles are currently in the thousands, but some estimates suggest that they could reach 10m worldwide by 2030. But that's just a tiny fraction of the more than one billion cars already on the road. So, the challenge is figuring out how to accommodate both humans and driverless vehicles on roads, pavements and bike paths. We've got several years, even decades, to get this right and self-driving vehicles that can operate without any human input at all are not on the immediate horizon. Engineers are still working out how to handle some of the most difficult challenges. Think about what happens at crossroads - when drivers and pedestrians arrive at the same time and use a combination of eye contact, gestures and intuition to navigate the junction safely. This type of reasoning stretches the abilities of machines. 10m predicted worldwide sales by 2025  100m UK government commitment to test projects 636,000 miles driven by Google cars in California last year Other challenges include weather conditions that disrupt sensors. And driverless vehicles will need to learn when to disobey traffic rules - for example, when an emergency vehicle needs everyone to move out of the way. Right now, autonomous vehicles are still very much in the testing phase, "learning" how to deal with the unpredictability that is endemic to driving. It's not something they have mastered and it's not uncommon for humans to have to take control in road tests to avoid accidents. There have been a handful of high profile incidents, including a fatality involving a semi-autonomous Tesla car, with most down to human error - such as running a red light. Officials are trying to get some ground rules in place for testing in public spaces, but even this may not be enough. It would take hundreds of years of road tests, over hundreds of billions of miles, to prove beyond doubt that driverless vehicles will cause fewer fatalities than human drivers, experts at think tank the Rand Corporation have argued. Instead, we may have to allow driverless vehicles in some circumstances, while they continue to learn. So far, there is no international safety standard for driverless vehicles - each country is responsible for writing its own rules. There are also questions about whether rules for driverless vehicles should be national - making it easier for companies to comply, or on a more local level - so that cities can tailor them to their residents' needs. This variety could speed up the process of learning about what works and what doesn't. Finding an agreement is difficult. Another issue without a clear answer is around the ethics that driverless vehicles should adopt. Put simply, in the case of an unavoidable accident, should a fully autonomous vehicle be programmed to career off the road, risking the lives of the four people inside, or continue into a parent and child crossing the road? Because human drivers make split second, instinctual decisions, we can't look to human behaviour to come up with the right answer. The shift from cars doing all the driving in predictable, stable conditions with humans as back-up, to a time when they make all the decisions will be gradual. Until cars are fully automated and don't need human input, manufacturers won't be able to dispense with steering and braking controls. People will still need driving licences and they'll have to ready to take control at short notice - so challenges like distraction and drunkenness will remain. It's likely we will always need seat belts: autonomous vehicles have the potential to dramatically reduce crashes, but no technology is perfect. The peril of driverless vehicles is that we will repeat the mistakes we've made over the last century - like rushing to build new roads that destroy neighbourhoods and creating out of town shopping centres that only cater to drivers. But if we learn from our mistakes we could reduce congestion, pollution, and inequality. When it comes to the self-driving vehicles, people will still have to be in the driver's seat. This analysis piece was commissioned by the BBC from an expert working for an outside organisation. Jennifer Bradley is the director of the Center for Urban Innovation at the Aspen Institute and the co-lead of the Bloomberg Aspen Initiative on Cities and Autonomous Vehicles, which is supported by Bloomberg Philanthropies. The Aspen Institute describes itself as a non-partisan forum for values-based leadership and the exchange of ideas.